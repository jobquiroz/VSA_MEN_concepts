{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the knowledge base into Hyperdimensional Vectors\n",
    "\n",
    "In this notebook the functions from the 'HDComputing' notebook are used to encode the McRae dataset. The following functions create an heteroassociative memory in which a knowledge base of Semantic Features representation of concepts is stored.\n",
    "\n",
    "### Importing libraries and HD computing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "#Only done once... \n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('wordnet_ic')\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "\n",
    "%run HDComputing_basics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranslateFeats(ListFeat):\n",
    "    \"It receives a list of features such as ['is_blue', 'is_rectangular'] and it returns: [['color','blue'], ['shape','rectangular']\"\n",
    "    # Dataframe for excel document\n",
    "    df = pd.read_excel(pathh + 'FEATS_brm.xlsx') #../McRaedataset/FEATS_brm.xlsx')\n",
    "    ListPairs = []\n",
    "    for feat in ListFeat:\n",
    "        # Row for feature...\n",
    "        row = df.loc[df['Feature'] == feat]       \n",
    "        # Look for values in vec_feat and vec_value\n",
    "        ListPairs.append([str(row['feat_name'].tolist()[0]), str(row['feat_value'].tolist()[0])])       \n",
    "    return ListPairs\n",
    "\n",
    "def ClosestConcepts (concept, nc):\n",
    "    \"Given a concept label, this function reads the distance matrix from McRae's and returns the 'nc' closests concepts in a list\"\n",
    "    # Excel document to data frame...\n",
    "    try:\n",
    "        df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','1st_200') #../McRaeDataset/cos_matrix_brm_IFR.xlsx', '1st_200')\n",
    "        ordered = df.sort_values(by=concept, ascending=False)[['CONCEPT', concept]]\n",
    "    except: \n",
    "        try:\n",
    "            df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','2nd_200') # ('../McRaeDataset/cos_matrix_brm_IFR.xlsx', '2nd_200')\n",
    "            ordered = df.sort_values(by=concept, ascending=False)[['CONCEPT', concept]]\n",
    "        except:\n",
    "            df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','last_141') #('../McRaeDataset/cos_matrix_brm_IFR.xlsx', 'last_141')\n",
    "            ordered = df.sort_values(by=concept, ascending=False)[['CONCEPT', concept]]\n",
    "    \n",
    "    L1 = list(ordered['CONCEPT'][0:nc])\n",
    "    L1 = map(str, L1)\n",
    "    L2 = zip(L1,list(ordered[concept][0:nc]))\n",
    "    L2 = map(list, L2)\n",
    "    \n",
    "    return L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding features\n",
    "\n",
    "### Normal encoding\n",
    "All features are included in definition\n",
    "\n",
    "(PONER ECUACIÃ“N....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDefinitions(max_num_feats, names_list): #Con_List is the list of concepts to encode... \n",
    "    \"Given an xlsx file it returns all the concepts feature values as they appear in the original dataset\"\n",
    "    #Dataframe for excel document\n",
    "    df = pd.read_excel( pathh + 'CONCS_FEATS_concstats_brm.xlsx') #../McRaeDataset/CONCS_FEATS_concstats_brm.xlsx') #MINI_\n",
    "    #Create a list with all concept names\n",
    "    #names = set(df['Concept'])\n",
    "    \n",
    "    # Extract list of features for each name\n",
    "    Concepts = []\n",
    "    for n in names_list:\n",
    "        row = df.loc[df['Concept'] == n]\n",
    "        Concepts.append([str(n), map(str,list(row['Feature']))[:max_num_feats]])\n",
    "    return Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar function for giving weights to features\n",
    "\n",
    "It repeats features within the feature's list...\n",
    "\n",
    "- If the list lenght (len) is less than or equal to 3 does nothing... [[feat_1 , val_1], [feat_2, val_2], [feat_2, val_2]] -> \" \"\n",
    "\n",
    "- If 3 < len <= 5 repeats first 2 two times... \n",
    "        [[feat_1, val_1],...,[feat_5, val_5]] -> [[feat_1, val_1], [feat_2, val_2], [feat_2, val_2], [feat_3, val_3], \n",
    "                                                 [feat_4, val_4], [feat_5, val_5]]\n",
    "                                                                                       \n",
    "- If 5 < len <= 8, repeats feat 1 and 2 three times, feats 3 and 4 twice and 5 - 8 once... \n",
    "\n",
    "- If 8 < len repeats feat 1 and 2 four times, 3 and 4 three times, 5 - 7 twice, and 8 -> once... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Repeat_features(selected_features):\n",
    "    \"It receives a list of features and returns with repeated elements. Repetition ensembles weight\"\n",
    "    L = []\n",
    "    if len(selected_features) <= 12:\n",
    "        return selected_features\n",
    "    elif len(selected_features) <= 16:\n",
    "        for i in range(len(selected_features)):\n",
    "            if i < 2:\n",
    "                L.extend([selected_features[i]]*2)\n",
    "            else:\n",
    "                L.extend([selected_features[i]])\n",
    "                \n",
    "    elif len(selected_features) <= 18:\n",
    "        for i in range(len(selected_features)):\n",
    "            if i < 2:\n",
    "                L.extend([selected_features[i]]*3)\n",
    "            elif i < 4:\n",
    "                L.extend([selected_features[i]]*2)\n",
    "            else:\n",
    "                L.extend([selected_features[i]])\n",
    "    else:\n",
    "        for i in range(len(selected_features)):\n",
    "            if i < 2:\n",
    "                L.extend([selected_features[i]]*4)\n",
    "            elif i < 4:\n",
    "                L.extend([selected_features[i]]*3)\n",
    "            elif i < 7:\n",
    "                L.extend([selected_features[i]]*2)\n",
    "            else:\n",
    "                L.extend([selected_features[i]])\n",
    "    return L\n",
    "\n",
    "def WeightFeatures2(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if 12 <= feat[1]:   #13... 15 muy bueno\n",
    "            L.extend([feat[0]] * 2)\n",
    "        else:\n",
    "            L.extend([feat[0]])\n",
    "    return L\n",
    "\n",
    "def WeightFeatures3(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if 19 <= feat[1]:\n",
    "            L.extend([feat[0]] * 3)\n",
    "        elif 9 <= feat[1]:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        else:\n",
    "            L.extend([feat[0]])\n",
    "    return L\n",
    "\n",
    "\n",
    "def WeightFeatures4(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if 19 <= feat[1]:\n",
    "            L.extend([feat[0]] * 4)\n",
    "        elif 13 <= feat[1]:\n",
    "            L.extend([feat[0]] * 3)\n",
    "        elif 9 <= feat[1]:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        else:\n",
    "            L.extend([feat[0]])\n",
    "    return L\n",
    "\n",
    "\n",
    "def WeightFeatures5(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\\\n",
    "    28 - 30 : 5 times   |   21 - 27 : 4 times  | 15 - 20 : 3 times  | 10 - 14 : 2 times | less than 9 : 1 time\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if 28 <= feat[1]:\n",
    "            L.extend([feat[0]] * 5)\n",
    "        elif 21 <= feat[1]:\n",
    "            L.extend([feat[0]] * 4)\n",
    "        elif 15 <= feat[1]:\n",
    "            L.extend([feat[0]] * 3)\n",
    "        elif 10 <= feat[1]:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        else:\n",
    "            L.extend([feat[0]])\n",
    "    return L\n",
    "\n",
    "def WeightFeatures6(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\\\n",
    "    28 - 30 : 5 times   |   21 - 27 : 4 times  | 15 - 20 : 3 times  | 10 - 14 : 2 times | less than 9 : 1 time\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if 28 <= feat[1]:\n",
    "            L.extend([feat[0]] * 6)\n",
    "        elif 24 <= feat[1]:\n",
    "            L.extend([feat[0]] * 5)\n",
    "        elif 18 <= feat[1]:\n",
    "            L.extend([feat[0]] * 4)\n",
    "        elif 13 <= feat[1]:\n",
    "            L.extend([feat[0]] * 3)\n",
    "        elif 9 <= feat[1]:\n",
    "            L.extend([feat[0]] * 2)    \n",
    "        else:\n",
    "            L.extend([feat[0]])\n",
    "    return L\n",
    "\n",
    "\n",
    "\n",
    "# FOR INTERCORR...\n",
    "def WeightFeatures_Interr2(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\\\n",
    "    28 - 30 : 5 times   |   21 - 27 : 4 times  | 15 - 20 : 3 times  | 10 - 14 : 2 times | less than 9 : 1 time\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if feat[1] >= 6:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        else:\n",
    "            L.extend([feat[0]])\n",
    "    return L\n",
    "\n",
    "def WeightFeatures_Interr3(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if feat[1] <= 100.0:\n",
    "            L.extend([feat[0]])\n",
    "        elif feat[1] <= 150.0:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        else:\n",
    "            L.extend([feat[0]] * 3)\n",
    "    return L\n",
    "\n",
    "def WeightFeatures_Interr4(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if feat[1] <= 50.0:\n",
    "            L.extend([feat[0]])\n",
    "        elif feat[1] <= 100.0:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        elif feat[1] <= 150.0:\n",
    "            L.extend([feat[0]] * 3)\n",
    "        else:\n",
    "            L.extend([feat[0]] * 4)\n",
    "    return L\n",
    "\n",
    "def WeightFeatures_Interr5(sel_features):\n",
    "    \"It receives a list of features-ProdFreq and returns with repeated elements based on the value of ProdFreq\\\n",
    "    28 - 30 : 5 times   |   21 - 27 : 4 times  | 15 - 20 : 3 times  | 10 - 14 : 2 times | less than 9 : 1 time\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if feat[1] <= 10.0:\n",
    "            L.extend([feat[0]])\n",
    "        elif feat[1] <= 50.0:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        elif feat[1] <= 100.0:\n",
    "            L.extend([feat[0]] * 3)\n",
    "        elif feat[1] <= 150.0:\n",
    "            L.extend([feat[0]] * 4)\n",
    "        else:\n",
    "            L.extend([feat[0]] * 5)\n",
    "    return L\n",
    "\n",
    "\n",
    "# Split in two... but combines PF and InterrCorr\n",
    "\n",
    "def WeightFeatures_PF_Interr(sel_features):\n",
    "    \"It receives a list of features-ProdFreq-InterCorr...\"\n",
    "    L = []\n",
    "    for feat in sel_features:\n",
    "        if feat[1] >= 13 or feat[2] >= 6:\n",
    "            L.extend([feat[0]] * 2)\n",
    "        else:\n",
    "            L.extend([feat[0]])\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by *Production Frequency (Prod_Freq)*\n",
    "\n",
    "We weight the features based on Production Frequency values... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDefs_ProdFreq(max_num_feats, names_list):\n",
    "    \"Given an xlsx file it returns all the concepts feature values as they appear in the original dataset\"\n",
    "    #Dataframe for excel document\n",
    "    df = pd.read_excel( pathh + 'CONCS_FEATS_concstats_brm.xlsx')\n",
    "    \n",
    "    Concepts = []\n",
    "    # Extract list of features for each concept\n",
    "    for name in names_list:\n",
    "        # Locating the concept by name\n",
    "        row = df.loc[df['Concept'] == name]\n",
    "        # Reading features and Rank_PF values\n",
    "        selected_features = row[['Feature','Prod_Freq']].values.tolist()\n",
    "        # Setting strings into an appropiate format\n",
    "        selected_features = map(lambda x: [str(x[0]), float(x[1])], selected_features) \n",
    "        # Sorting\n",
    "        selected_features = sorted(selected_features, key = lambda x : x[1], reverse = True)\n",
    "        \n",
    "        # It keeps Prof_Freq value... \n",
    "        Concepts.append([str(name), WeightFeatures2(selected_features[:max_num_feats])]) \n",
    "        \n",
    "    return Concepts\n",
    "\n",
    "# pathh = '../Data/' \n",
    "# L = ['tomato']\n",
    "# Defs = ReadDefs_ProdFreq(22, L)\n",
    "# print Defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by *Intercorr_str_tax*\n",
    "\n",
    "According to McRae dataset this variable: measures \"*intercorrelational strength of feature for that concept*\"\n",
    "Not combining... pure Intercorr_str_tax and conditions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDefs_Intercorr_str (max_num_feats, names_list):\n",
    "    \"Given an xlsx file it returns all the concepts feature values as they appear in the original dataset\"\n",
    "    #Dataframe for excel document\n",
    "    df = pd.read_excel( pathh + 'CONCS_FEATS_concstats_brm.xlsx')\n",
    "    \n",
    "    Concepts = []\n",
    "    # Extract list of features for each concept\n",
    "    for name in names_list:\n",
    "        # Locating the concept by name\n",
    "        row = df.loc[df['Concept'] == name]\n",
    "        \n",
    "        # Reading features and Rank_PF values\n",
    "        selected_features = row[['Feature','Intercorr_Str_Tax']].values.tolist()\n",
    "        \n",
    "        # Setting strings into an appropiate format\n",
    "        selected_features = map(lambda x: [str(x[0]), float(x[1])], selected_features) \n",
    "        \n",
    "        # Sorting by Intercorr_Str_Tax...\n",
    "        selected_features = sorted(selected_features, key = lambda x: x[1])[:max_num_feats]\n",
    "\n",
    "        # Creating final representation \n",
    "        Concepts.append([str(name), WeightFeatures_Interr2(selected_features)]) \n",
    "    return Concepts\n",
    "# pathh = '../Data/' \n",
    "# L = ['tomato']\n",
    "# Defs = ReadDefs_Intercorr_str(22, L)\n",
    "# print Defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting by *Intercorr_str_no_tax*\n",
    "\n",
    "According to McRae dataset this variable: measures \"*intercorrelational strength of feature for that concept*\"\n",
    "Not combining... pure Intercorr_str_No_tax and conditions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDefs_Intercorr_NoT_str (max_num_feats, names_list):\n",
    "    \"Given an xlsx file it returns all the concepts feature values as they appear in the original dataset\"\n",
    "    #Dataframe for excel document\n",
    "    df = pd.read_excel( pathh + 'CONCS_FEATS_concstats_brm.xlsx')\n",
    "    \n",
    "    Concepts = []\n",
    "    # Extract list of features for each concept\n",
    "    for name in names_list:\n",
    "        # Locating the concept by name\n",
    "        row = df.loc[df['Concept'] == name]\n",
    "        \n",
    "        # Reading features and Rank_PF values\n",
    "        selected_features = row[['Feature','Intercorr_Str_No_Tax']].values.tolist()\n",
    "        \n",
    "        # Setting strings into an appropiate format\n",
    "        selected_features = map(lambda x: [str(x[0]), float(x[1])], selected_features) \n",
    "        \n",
    "        # Sorting by Intercorr_Str_Tax...\n",
    "        selected_features = sorted(selected_features, key = lambda x: x[1])[:max_num_feats]\n",
    "\n",
    "        # Creating final representation \n",
    "        Concepts.append([str(name), WeightFeatures_Interr2(selected_features)]) \n",
    "    return Concepts\n",
    "# pathh = '../Data/' \n",
    "# L = ['tomato']\n",
    "# Defs = ReadDefs_Intercorr_str(22, L)\n",
    "# print Defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining *Intercorr_str_tax* and *Prof_Freq*\n",
    "\n",
    "In this function we complement the features selected based on the *Intercorr_str_tax* variable with features selected based on frequency of mention, that is to say *Rank_PF*.\n",
    "The goal is for each concept to have at least **6** features. For those concepts where the *Intercorr_str_tax* variable does not provide with 6 features, we complement the list of features by selecting the rest based on Rank_PF (frequency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadDefs_Intercorr_PF (max_num_feats, names_list):\n",
    "    \"Given an xlsx file it returns all the concepts feature values as they appear in the original dataset\"\n",
    "    #Dataframe for excel document\n",
    "    df = pd.read_excel( pathh + 'CONCS_FEATS_concstats_brm.xlsx')\n",
    "    \n",
    "    Concepts = []\n",
    "    # Extract list of features for each concept\n",
    "    for name in names_list:\n",
    "        # Locating the concept by name\n",
    "        row = df.loc[df['Concept'] == name]\n",
    "        \n",
    "        # Reading features and Rank_PF values\n",
    "        selected_features = row[['Feature','Prod_Freq','Intercorr_Str_Tax']].values.tolist()\n",
    "        # Setting strings into an appropiate format\n",
    "        selected_features = map(lambda x: [str(x[0]), int(x[1]), float(x[2])], selected_features) \n",
    "        \n",
    "        # Creating final representation \n",
    "        Concepts.append([str(name), WeightFeatures_PF_Interr(selected_features[:max_num_feats])]) \n",
    "    return Concepts\n",
    "\n",
    "# Combining with Intercorr No Tax... \n",
    "def ReadDefs_Intercorr_NoT_PF (max_num_feats, names_list):\n",
    "    \"Given an xlsx file it returns all the concepts feature values as they appear in the original dataset\"\n",
    "    #Dataframe for excel document\n",
    "    df = pd.read_excel( pathh + 'CONCS_FEATS_concstats_brm.xlsx')\n",
    "    \n",
    "    Concepts = []\n",
    "    # Extract list of features for each concept\n",
    "    for name in names_list:\n",
    "        # Locating the concept by name\n",
    "        row = df.loc[df['Concept'] == name]\n",
    "        \n",
    "        # Reading features and Rank_PF values\n",
    "        selected_features = row[['Feature','Prod_Freq','Intercorr_Str_No_Tax']].values.tolist()\n",
    "        # Setting strings into an appropiate format\n",
    "        selected_features = map(lambda x: [str(x[0]), int(x[1]), float(x[2])], selected_features) \n",
    "        \n",
    "        # Creating final representation \n",
    "        Concepts.append([str(name), WeightFeatures_PF_Interr(selected_features[:max_num_feats])]) \n",
    "    return Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing ID vectors into memory\n",
    "\n",
    "### Creating definitions dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDictionary( mode , max_num_feats, names_list):\n",
    "    global Dict_defs\n",
    "    if mode == 'normal':\n",
    "        data = ReadDefinitions(max_num_feats, names_list)\n",
    "    elif mode == 'Prod_Freq':\n",
    "        data = ReadDefs_ProdFreq(max_num_feats, names_list)\n",
    "    elif mode == 'Intercorr_str_tax':\n",
    "        data = ReadDefs_Intercorr_str(max_num_feats, names_list)\n",
    "    elif mode == 'Intercorr_str_No_tax':\n",
    "        data = ReadDefs_Intercorr_NoT_str(max_num_feats, names_list)\n",
    "    elif mode == 'Intercorr_PF':\n",
    "        data = ReadDefs_Intercorr_PF(max_num_feats, names_list)\n",
    "    elif mode == 'Intercorr_NoT_PF':\n",
    "        data = ReadDefs_Intercorr_NoT_PF(max_num_feats, names_list)\n",
    "        \n",
    "    for concept in data:\n",
    "        Dict_defs[concept[0]] = TranslateFeats(concept[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list (L):\n",
    "    \"Recursive function that flats a list of lists (at any level)\"\n",
    "    if L == []:\n",
    "        return L\n",
    "    if type(L[0]) is list:\n",
    "        return flat_list(L[0]) + flat_list(L[1:])\n",
    "    return L[:1] + flat_list(L[1:])\n",
    "\n",
    "def FeatureVectors(Dic):\n",
    "    \"It extract from the definition dictionary all the feature type vectors ('is','has','color', etc...)\"\n",
    "    global feature_vectors\n",
    "    featt = []\n",
    "    vals = Dic.values()\n",
    "    for l in vals:\n",
    "        for p in l:\n",
    "            featt.append(p[0])\n",
    "    feature_vectors = list(set(featt))\n",
    "    \n",
    "    \n",
    "def SaveConcepts(Dic):\n",
    "    \"\"\"Given a definitions dictionary it stores in memory the entire set of concepts in the dictionary (including feature vectors)\"\"\"\n",
    "    keys = Dic.keys()\n",
    "    vals = Dic.values()\n",
    "    all_concepts = list(set(flat_list(vals) + keys))\n",
    "    # Process for storing list of concepts in memory\n",
    "    for concept in all_concepts:\n",
    "        HDvector(N,concept) #This creates an object and store it in memory    \n",
    "    \n",
    "def CreateSemanticPointer (PairList):\n",
    "    \"Turns list as [[feat1,feat_val],[feat2,feat_val],[feat3,feat_val]] into vector feat1*feat_val + feat2*feat_val ...\"\n",
    "    if len(PairList) == 0:\n",
    "        return HDvector(N)\n",
    "    vecs = []\n",
    "    for pair in PairList:\n",
    "        vecs.append(Dict[pair[0]] * Dict[pair[1]])\n",
    "    return ADD(vecs)\n",
    "\n",
    "def SaveDefinitions(Dic):\n",
    "    \"\"\"Given the definitions dictionary, and having all its concepts previously stored in memory, this functions\n",
    "       creates a definition vector (semantic pointer) using HD operations and assign it as a pointer to an \n",
    "       object vector (ID vector).\"\"\"\n",
    "    global feature_vectors\n",
    "    # Going through all elements in dictionary\n",
    "    for key, value in Dic.iteritems():\n",
    "        Dict[key].setPointer(CreateSemanticPointer(value))\n",
    "        \n",
    "def NormalizeHammDist (Dist_list):\n",
    "    \"Given a distance list of the form [['name', dist], ['name', dist], ... ], it normalize each distance and return a list with the same form\"\n",
    "    for i in range(len(Dist_list)):\n",
    "        Dist_list[i][1] = round( 1. - Dist_list[i][1] / float(N), 3 ) \n",
    "    return Dist_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Init_mem( mode = 'normal', max_num_feats = 100 , names_list = None):\n",
    "    init()\n",
    "    print \"Begining to encode dataset...\"\n",
    "    thr = 0.45 * N\n",
    "    # Read dataset and create definition dictionary\n",
    "    CreateDictionary( mode, max_num_feats, names_list )\n",
    "    # Feature vectors\n",
    "    FeatureVectors(Dict_defs)\n",
    "    # Save concepts into memory (ID vectors)\n",
    "    SaveConcepts(Dict_defs)\n",
    "    # Associate definitions to concepts into memory (SP vectors)\n",
    "    SaveDefinitions(Dict_defs)\n",
    "    print \"End of encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading similarity from distance matrix (McRae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def McRae_simi (pair_concepts):\n",
    "    \"Given a pair of concepts (in a list) it consults the similarity from the cos_matrix... file\"\n",
    "    try: \n",
    "        df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','1st_200')\n",
    "        return list(df.loc[df['CONCEPT'] == pair_concepts[0]][pair_concepts[1]])[0]\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','2nd_200')\n",
    "            return list(df.loc[df['CONCEPT'] == pair_concepts[0]][pair_concepts[1]])[0]\n",
    "        except:\n",
    "            df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','last_141')\n",
    "            return list(df.loc[df['CONCEPT'] == pair_concepts[0]][pair_concepts[1]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic similarity using NLTK library functions\n",
    "### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "def get_concepts_list ():\n",
    "    \"Returns a list of strings: the names of the concepts\"\n",
    "    df = pd.read_excel(pathh + 'CONCS_Synset_brm.xlsx') #../McRaedataset/CONCS_Synset_brm.xlsx')\n",
    "    return map(str, list(df['Concept']))\n",
    "    \n",
    "def get_synset (concept):\n",
    "    \"Given a concept name (string) it returns its synset (string)\"\n",
    "    # Dataframe for excel document\n",
    "    df = pd.read_excel(pathh + 'CONCS_Synset_brm.xlsx') #../McRaedataset/CONCS_Synset_brm.xlsx')\n",
    "    row = df.loc[df['Concept'] == concept]\n",
    "    return str(list(row['Synset'] )[0])\n",
    "\n",
    "def apply_sim_metric ( similarity_metric, num, in_concept, corpus = None):\n",
    "    \"Given a similarity_metric function it returns a list of the num closest concepts to 'concept'\"\n",
    "    dist_list = []\n",
    "    for c in Concepts:\n",
    "        c_synset = wn.synset( get_synset(c) )\n",
    "        if corpus:\n",
    "            dist_list.append([c, round(similarity_metric(in_concept, c_synset, corpus), 3) ])\n",
    "        else:\n",
    "            dist_list.append([c, round(similarity_metric(in_concept, c_synset), 3) ])\n",
    "    return sorted(dist_list, key = lambda r : r[1], reverse = True ) [:num]\n",
    "\n",
    "def similarity_fun ( similarity_metric, pair, corpus = None):\n",
    "    \"Given a similarity_metric function it returns a list of the num closest concepts to 'concept'\"\n",
    "    c_synset_1 = wn.synset( get_synset(pair[0]))\n",
    "    c_synset_2 = wn.synset( get_synset(pair[1]))\n",
    "    if corpus:\n",
    "        return round(similarity_metric(c_synset_1, c_synset_2, corpus), 3)\n",
    "    else:\n",
    "        return round(similarity_metric(c_synset_1, c_synset_2), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
